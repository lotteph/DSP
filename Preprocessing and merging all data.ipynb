{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ae95ed",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a1ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(df_holiday2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f011fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='once')\n",
    "plt.style.use('seaborn-poster')\n",
    "sns.set_context(\"poster\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061aff6b",
   "metadata": {},
   "source": [
    "### Preprocess, merge and clean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3098a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessGVB(path_url):\n",
    "    return path_url\n",
    "\n",
    "def preprocessWeather(path_url):\n",
    "    '''\n",
    "    Reads in and preprocesses the weather data\n",
    "    \n",
    "    :path_url: The path_url to the weather data\n",
    "    \n",
    "    Returns a preprocessed Dataframe\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(path_url)\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    df[['FH', 'T', 'RH']] = df[['FH', 'T', 'RH']] / 10\n",
    "    df['YYYYMMDD'] = pd.to_datetime(df['YYYYMMDD'], format='%Y%m%d')\n",
    "    df['date'] = df['YYYYMMDD'] +  pd.to_timedelta(df['HH'], unit='h')\n",
    "    df.drop(columns = ['#STN', 'DD', 'FF', 'FX', 'T10N', 'TD', 'Q', \n",
    "                       'P', 'VV', 'U', 'WW', 'IX', 'HH', 'YYYYMMDD'], inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocessResono(path_url):\n",
    "    '''\n",
    "    Reads in and preprocesses the resono data\n",
    "    \n",
    "    :path_url: The path_url to the resono data\n",
    "    \n",
    "    Returns a preprocessed Dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(path_url)\n",
    "    df = df.drop(columns = [\"Unnamed: 0\"])\n",
    "    \n",
    "    df['End'] = pd.to_datetime(df['End'])\n",
    "    df['End'] = pd.to_datetime(df['End'].dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    df = df.rename(columns = {'End' : 'Datetime',\n",
    "                              'End_Dates' : 'Date',\n",
    "                              'End_Time' : 'Time'})\n",
    "    df = df.set_index('Datetime')\n",
    "    df = df.loc['2020-10':]\n",
    "    \n",
    "    df = df[df.Location != 'Vondelpark Oost']\n",
    "    df = df[df.Location != 'Westerpark']\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocessHoliday(path_url):\n",
    "    holiday = pd.read_csv(path_url)\n",
    "    holiday = holiday.drop(['Unnamed: 0'], axis = 1)\n",
    "    holiday = holiday.drop([0,28,120,122, 128, 150,219,221,227],axis=0)\n",
    "    holiday['Holiday_Name'] = holiday['Holiday_Name'].str.replace('Boxing Day', 'Christmas Day')\n",
    "    return holiday\n",
    "\n",
    "def mergeGVBdata(gvb, resono):\n",
    "    return gvb\n",
    "\n",
    "def mergeWeatherFiles(df_Weather2020, df_Weather2021):\n",
    "    '''\n",
    "    Merges the weather data\n",
    "    \n",
    "    :df_Weather2020: Weather data from 2020\n",
    "    :df_Weather2021: Weather data from 2021\n",
    "    \n",
    "    Returns a merged weather Dataframe\n",
    "    '''\n",
    "    \n",
    "    df_weather = pd.concat([df_Weather2020, df_Weather2021], axis=0)\n",
    "    df_weather = df_weather.loc['2020-10':]\n",
    "\n",
    "    cols_int = ['SQ', 'DR', 'N', 'M', 'R', 'S', 'O', 'Y']\n",
    "    cols_float = ['FH', 'T']\n",
    "\n",
    "    df_weather[cols_float] = df_weather[cols_float].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    df_weather[cols_int] = df_weather[cols_int].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    df_weather['RH'] = df_weather['RH'].apply(lambda x: 0.05 if x==-0.1 else x)\n",
    "    \n",
    "    df_weather_resample = pd.concat([df_weather[['FH', 'T', 'N']].resample('15T').interpolate(method='linear'),\n",
    "                    df_weather[['RH', 'DR', 'SQ', 'M', 'R', 'S', 'O', 'Y']].resample('15T').bfill()],\n",
    "                   axis=1)\n",
    "    \n",
    "    df_weather_resample[['DR', 'SQ']] = df_weather_resample[['DR', 'SQ']] * 1.5\n",
    "    df_weather_resample['RH'] = df_weather_resample['RH'] / 4\n",
    "    \n",
    "    return df_weather_resample \n",
    "\n",
    "def mergeWeatherResonoHoliday(df_resono, df_weather, df_holiday):\n",
    "    '''\n",
    "    Merges the resono and weather data\n",
    "    \n",
    "    :df_resono: All resono data\n",
    "    :df_weather: All weather data\n",
    "    :df_holiday: All holiday data\n",
    "    \n",
    "    Returns a merged weather Dataframe\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    merge_resono_weather = pd.merge(df_resono, df_weather, left_index=True, right_index=True, how='left')\n",
    "    merge_resono_weather = merge_resono_weather.rename({'T': 'Temperature', 'N': 'Clouds', 'FH': 'Windspeed',\n",
    "                                                    'RH': 'Rain amount', 'DR': 'Rain duration' , 'SQ': 'Sun duration',\n",
    "                                                    'M': 'Fog', 'R': 'Rain', 'S': 'Snow', 'O': 'Thunder', 'Y': 'Ice'},\n",
    "                                                   axis=1) \n",
    "    \n",
    "    all_merged = pd.merge(merge_resono_weather, df_holiday, how='left', right_on = 'End_Dates', left_on='Date')\n",
    "    all_merged = all_merged.drop(['End_Dates'], axis=1)\n",
    "    return all_merged\n",
    "\n",
    "def Target_OneHotEncoding(Resono_Holi):\n",
    "    #fill the blank of Holiday count, year, month, day\n",
    "    Resono_Holi['Holiday_Count'] = Resono_Holi['Holiday_Count'].replace(np.nan, 0)\n",
    "    Resono_Holi['Year'] = pd.to_datetime(Resono_Holi['Date']).dt.year\n",
    "    Resono_Holi['Month'] = pd.to_datetime(Resono_Holi['Date']).dt.month\n",
    "    Resono_Holi['Day'] = pd.to_datetime(Resono_Holi['Date']).dt.day\n",
    "    \n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                             ['Christmas Day', 'New year', 'Boxing Day', 'Holiday_Name_New year', 'Christmas holiday', 'Holiday_Name_Boxing Day'] ,'Winter holiday')\n",
    "\n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                                 [\"King's day\"] ,'Kings day')\n",
    "\n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                                 ['Easter Monday', 'Easter Sunday'] ,'Easter')\n",
    "\n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                                 ['Whit Monday', 'Whit Sunday'] ,'Whit')\n",
    "\n",
    "    '''\n",
    "    Monday =0, Tuesday=1, Wednesday=2,Thursday =3,  Friday=4 ,  Saturday =5, Sunday =6\n",
    "    '''\n",
    "\n",
    "    Resono_Holi['Date'] = Resono_Holi['Date'].astype('datetime64[ns]')\n",
    "\n",
    "    encoder = ce.TargetEncoder(cols='Holiday_Name')\n",
    "    Resono_Holi['Holiday_name'] = encoder.fit_transform(Resono_Holi['Holiday_Name'], Resono_Holi['Visits'])\n",
    "    \n",
    "    # Holidays\n",
    "    Resono_Holi_Dummies = pd.get_dummies(Resono_Holi, columns=[\"Holiday_Name\"])\n",
    "\n",
    "    return Resono_Holi_Dummies\n",
    "\n",
    "def remove_outliers(df, gamma=0.01, nu=0.03):\n",
    "    '''\n",
    "    Remove outliers with a One-Class SVM.\n",
    "    \n",
    "    :df: Dataframe to perform outlier detection on\n",
    "    :gamma: Value of the kernel coefficient for ‘rbf’ (default = 0.01)\n",
    "    :nu: Percentage of the data to be classified as outliers (default = 0.03)\n",
    "    \n",
    "    Returns\n",
    "    :df_detected: Dataframe with the outliers replaced by NaN\n",
    "    :outlier_index: List of the indexes of the outliers (used for plotting the outliers, probably \n",
    "                                                         not necessary for final product)\n",
    "    '''\n",
    "    model = OneClassSVM(kernel='rbf', gamma=gamma, nu=nu)\n",
    "    df_detected = df.copy()\n",
    "    \n",
    "    for idx, loc in enumerate(df.columns):\n",
    "        dt = df[loc]\n",
    "        dt_detected = dt.copy()\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        dt_scaled = scaler.fit_transform(dt.values.reshape(-1,1))\n",
    "            \n",
    "        fit = model.fit(dt_scaled)\n",
    "        pred = fit.predict(dt_scaled)\n",
    "        outlier_index = np.where(pred == -1)\n",
    "        \n",
    "        if len(outlier_index) != len(dt_detected):\n",
    "            dt_detected.iloc[outlier_index] = np.nan\n",
    "    \n",
    "        df_detected[loc] = dt_detected\n",
    "        \n",
    "    return df_detected#, outlier_index\n",
    "\n",
    "def interpolate_df(df, backfill=False):\n",
    "    '''\n",
    "    Interpolate the NaN values in the dataframe with either backfilling or linear interpolation.\n",
    "    \n",
    "    :df: Dataframe to be interpolated\n",
    "    :backfill: Bool, if true, interpolate with backfilling, otherwise use linear interpolation (default = False)\n",
    "    \n",
    "    Returns a Dataframe with interpolated values\n",
    "    '''\n",
    "    df_int = df.copy()\n",
    "    \n",
    "    if backfill == True:\n",
    "        df_int = df_int.backfill()\n",
    "        \n",
    "    else:\n",
    "        for idx, loc in enumerate(df.columns):\n",
    "            dt = df[loc]\n",
    "            dt_int = dt.copy()\n",
    "            dt_int = dt_int.interpolate()\n",
    "            df_int[loc] = dt_int\n",
    "        \n",
    "    return df_int\n",
    "\n",
    "def smooth_df(df, N=3):\n",
    "    '''\n",
    "    Smooth the data with a rolling average to remove false peaks in the data\n",
    "    \n",
    "    :df: Dataframe to be smoothed\n",
    "    :N: Size of the moving window (default = 3)\n",
    "    \n",
    "    Returns a smoothed Dataframe\n",
    "    '''\n",
    "    df_smooth = df.copy()\n",
    "    df_smooth = df_smooth.rolling(N).mean()\n",
    "    \n",
    "    begin_vals = df.iloc[:N-1]\n",
    "    df_smooth.update(begin_vals)\n",
    "        \n",
    "    return df_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55854f",
   "metadata": {},
   "source": [
    "### Reading in filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca1b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\my-r-env\\lib\\site-packages\\ipykernel_launcher.py:1: DtypeWarning: Columns (15,16,20,21,22,23,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\olivi\\anaconda3\\envs\\my-r-env\\lib\\site-packages\\ipykernel_launcher.py:42: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n"
     ]
    }
   ],
   "source": [
    "df_Weather2020 = preprocessWeather(\"KNMI (Weather) 2020-2021/uurgeg_240_2011-2020.txt\")\n",
    "df_Weather2021 = preprocessWeather(\"KNMI (Weather) 2020-2021/uurgeg_240_2021-2030.txt\")\n",
    "df_resono = preprocessResono(\"resono_2020_2022.csv\")\n",
    "df_holiday = preprocessHoliday('holidays.csv')\n",
    "\n",
    "df_weather = mergeWeatherFiles(df_Weather2020, df_Weather2021)\n",
    "df_resono_weather = mergeWeatherResonoHoliday(df_resono, df_weather, df_holiday)\n",
    "dataframe = Target_OneHotEncoding(df_resono_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8b226ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lines add the complete date to a new column, used for merging with weather/holidays\n",
    "\n",
    "# dataframe[\"Date\"] = dataframe[\"Date\"].astype('str')\n",
    "# dataframe['Datetime']=pd.to_datetime(dataframe.Date + ' ' + dataframe.Time, format='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5729926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = remove_outliers(dataframe[['Visits']])\n",
    "df_no_outliers_int = interpolate_df(df_no_outliers, backfill=False)\n",
    "\n",
    "df_resono_no_outliers = dataframe.copy()\n",
    "df_resono_no_outliers['Visits'] = df_no_outliers_int['Visits']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
