{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ae95ed",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a1ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from functionsPredictions import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(df_holiday2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c61a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f011fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='once')\n",
    "plt.style.use('seaborn-poster')\n",
    "sns.set_context(\"poster\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061aff6b",
   "metadata": {},
   "source": [
    "### Preprocess, merge and clean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3098a5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessGVB(path_url):\n",
    "    return path_url\n",
    "\n",
    "def preprocessWeather(path_url):\n",
    "    '''\n",
    "    Reads in and preprocesses the weather data\n",
    "    \n",
    "    :path_url: The path_url to the weather data\n",
    "    \n",
    "    Returns a preprocessed Dataframe\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(path_url)\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    df[['FH', 'T', 'RH']] = df[['FH', 'T', 'RH']] / 10\n",
    "    df['YYYYMMDD'] = pd.to_datetime(df['YYYYMMDD'], format='%Y%m%d')\n",
    "    df['date'] = df['YYYYMMDD'] +  pd.to_timedelta(df['HH'], unit='h')\n",
    "    df.drop(columns = ['#STN', 'DD', 'FF', 'FX', 'T10N', 'TD', 'Q', \n",
    "                       'P', 'VV', 'U', 'WW', 'IX', 'HH', 'YYYYMMDD'], inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocessResono(path_url):\n",
    "    '''\n",
    "    Reads in and preprocesses the resono data\n",
    "    \n",
    "    :path_url: The path_url to the resono data\n",
    "    \n",
    "    Returns a preprocessed Dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(path_url)\n",
    "    df = df.drop(columns = [\"Unnamed: 0\"])\n",
    "    \n",
    "    df['End'] = pd.to_datetime(df['End'])\n",
    "    df['End'] = pd.to_datetime(df['End'].dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    df = df.rename(columns = {'End' : 'Datetime',\n",
    "                              'End_Dates' : 'Date',\n",
    "                              'End_Time' : 'Time'})\n",
    "    df = df.set_index('Datetime')\n",
    "    df = df.loc['2020-10':]\n",
    "    \n",
    "    df = df[df.Location != 'Vondelpark Oost']\n",
    "    df = df[df.Location != 'Westerpark']\n",
    "    df = df[df.Location != 'Rembrandtpark Noord']\n",
    "    df = df[df.Location != 'Rembrandtpark Zuid']\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocessHoliday(path_url):\n",
    "    holiday = pd.read_csv(path_url)\n",
    "    holiday = holiday.drop(['Unnamed: 0'], axis = 1)\n",
    "    holiday = holiday.drop([0,28,120,122, 128, 150,219,221,227],axis=0)\n",
    "    holiday['Holiday_Name'] = holiday['Holiday_Name'].str.replace('Boxing Day', 'Christmas Day')\n",
    "    return holiday\n",
    "\n",
    "def mergeGVBdata(gvb, resono):\n",
    "    return gvb\n",
    "\n",
    "def mergeWeatherFiles(df_Weather2020, df_Weather2021):\n",
    "    '''\n",
    "    Merges the weather data\n",
    "    \n",
    "    :df_Weather2020: Weather data from 2020\n",
    "    :df_Weather2021: Weather data from 2021\n",
    "    \n",
    "    Returns a merged weather Dataframe\n",
    "    '''\n",
    "    \n",
    "    df_weather = pd.concat([df_Weather2020, df_Weather2021], axis=0)\n",
    "    df_weather = df_weather.loc['2020-10':]\n",
    "\n",
    "    cols_int = ['SQ', 'DR', 'N', 'M', 'R', 'S', 'O', 'Y']\n",
    "    cols_float = ['FH', 'T']\n",
    "\n",
    "    df_weather[cols_float] = df_weather[cols_float].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    df_weather[cols_int] = df_weather[cols_int].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    df_weather['RH'] = df_weather['RH'].apply(lambda x: 0.05 if x==-0.1 else x)\n",
    "    \n",
    "    df_weather_resample = pd.concat([df_weather[['FH', 'T', 'N']].resample('15T').interpolate(method='linear'),\n",
    "                    df_weather[['RH', 'DR', 'SQ', 'M', 'R', 'S', 'O', 'Y']].resample('15T').bfill()],\n",
    "                   axis=1)\n",
    "    \n",
    "    df_weather_resample[['DR', 'SQ']] = df_weather_resample[['DR', 'SQ']] * 1.5\n",
    "    df_weather_resample['RH'] = df_weather_resample['RH'] / 4\n",
    "    \n",
    "    return df_weather_resample \n",
    "\n",
    "def mergeWeatherResonoHoliday(df_resono, df_weather, df_holiday):\n",
    "    '''\n",
    "    Merges the resono and weather data\n",
    "    \n",
    "    :df_resono: All resono data\n",
    "    :df_weather: All weather data\n",
    "    :df_holiday: All holiday data\n",
    "    \n",
    "    Returns a merged weather Dataframe\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    merge_resono_weather = pd.merge(df_resono, df_weather, left_index=True, right_index=True, how='left')\n",
    "    merge_resono_weather = merge_resono_weather.rename({'T': 'Temperature', 'N': 'Clouds', 'FH': 'Windspeed',\n",
    "                                                    'RH': 'Rain amount', 'DR': 'Rain duration' , 'SQ': 'Sun duration',\n",
    "                                                    'M': 'Fog', 'R': 'Rain', 'S': 'Snow', 'O': 'Thunder', 'Y': 'Ice'},\n",
    "                                                   axis=1) \n",
    "    \n",
    "    all_merged = pd.merge(merge_resono_weather, df_holiday, how='left', right_on = 'End_Dates', left_on='Date')\n",
    "    all_merged = all_merged.drop(['End_Dates'], axis=1)\n",
    "    return all_merged\n",
    "\n",
    "def Target_OneHotEncoding(Resono_Holi):\n",
    "    #fill the blank of Holiday count, year, month, day\n",
    "    Resono_Holi['Holiday_Count'] = Resono_Holi['Holiday_Count'].replace(np.nan, 0)\n",
    "    Resono_Holi['Year'] = pd.to_datetime(Resono_Holi['Date']).dt.year\n",
    "    Resono_Holi['Month'] = pd.to_datetime(Resono_Holi['Date']).dt.month\n",
    "    Resono_Holi['Day'] = pd.to_datetime(Resono_Holi['Date']).dt.day\n",
    "    \n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                             ['Christmas Day', 'New year', 'Boxing Day', 'Holiday_Name_New year', 'Christmas holiday', 'Holiday_Name_Boxing Day'] ,'Winter holiday')\n",
    "\n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                                 [\"King's day\"] ,'Kings day')\n",
    "\n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                                 ['Easter Monday', 'Easter Sunday'] ,'Easter')\n",
    "\n",
    "    Resono_Holi['Holiday_Name'] = Resono_Holi['Holiday_Name'].replace(\n",
    "                                 ['Whit Monday', 'Whit Sunday'] ,'Whit')\n",
    "\n",
    "    Resono_Holi['Date'] = Resono_Holi['Date'].astype('datetime64[ns]')\n",
    "\n",
    "    encoder = ce.TargetEncoder(cols='Holiday_Name')\n",
    "    Resono_Holi['Holiday_name'] = encoder.fit_transform(Resono_Holi['Holiday_Name'], Resono_Holi['Visits'])\n",
    "    \n",
    "    # Holidays\n",
    "    Resono_Holi_Dummies = pd.get_dummies(Resono_Holi, columns=[\"Holiday_Name\"])\n",
    "\n",
    "    return Resono_Holi_Dummies\n",
    "\n",
    "def remove_outliers(df, gamma=0.01, nu=0.03):\n",
    "    '''\n",
    "    Remove outliers for each location with a One-Class SVM.\n",
    "    \n",
    "    :df: Dataframe to perform outlier detection on\n",
    "    :gamma: Value of the kernel coefficient for ‘rbf’ (default = 0.01)\n",
    "    :nu: Percentage of the data to be classified as outliers (default = 0.03)\n",
    "    \n",
    "    Returns\n",
    "    :df_detected: Dataframe with the outliers replaced by NaN\n",
    "    :outlier_index: List of the indexes of the outliers (used for plotting the outliers, probably \n",
    "                                                         not necessary for final product)\n",
    "    '''\n",
    "    model = OneClassSVM(kernel='rbf', gamma=gamma, nu=nu)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    for loc in list(set(df.Location)):\n",
    "        dt = df[(df.Location == loc)]\n",
    "        dt_detected = dt.copy()\n",
    "\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        dt_scaled = scaler.fit_transform(dt['Visits'].values.reshape(-1,1))\n",
    "\n",
    "        fit = model.fit(dt_scaled)\n",
    "        pred = fit.predict(dt_scaled)\n",
    "        outlier_index = np.where(pred == -1)\n",
    "        idx = dt.iloc[outlier_index].index\n",
    "        df.loc[idx, 'Visits'] = np.nan\n",
    "        \n",
    "    df = df.set_index('Datetime')\n",
    "    return df\n",
    "\n",
    "def interpolate_df(df, backfill=False):\n",
    "    '''\n",
    "    Interpolate the NaN values in the dataframe with either backfilling or linear interpolation.\n",
    "    \n",
    "    :df: Dataframe to be interpolated\n",
    "    :backfill: Bool, if true, interpolate with backfilling, otherwise use linear interpolation (default = False)\n",
    "    \n",
    "    Returns a Dataframe with interpolated values\n",
    "    '''\n",
    "    df_int = df.copy()\n",
    "    \n",
    "    if backfill == True:\n",
    "        df_int = df_int.backfill()\n",
    "        \n",
    "    else:\n",
    "        for idx, loc in enumerate(df.columns):\n",
    "            dt = df[loc]\n",
    "            dt_int = dt.copy()\n",
    "            dt_int = dt_int.interpolate()\n",
    "            df_int[loc] = dt_int\n",
    "        \n",
    "    return df_int\n",
    "\n",
    "def smooth_df(df, N=3):\n",
    "    '''\n",
    "    Smooth the data with a rolling average to remove false peaks in the data\n",
    "    \n",
    "    :df: Dataframe to be smoothed\n",
    "    :N: Size of the moving window (default = 3)\n",
    "    \n",
    "    Returns a smoothed Dataframe\n",
    "    '''\n",
    "    df_smooth = df.copy()\n",
    "    df_smooth = df_smooth.rolling(N).mean()\n",
    "    \n",
    "    begin_vals = df.iloc[:N-1]\n",
    "    df_smooth.update(begin_vals)\n",
    "        \n",
    "    return df_smooth\n",
    "\n",
    "def add_time_vars(data, onehot=True):\n",
    "    '''\n",
    "    Adds columns for the month and weekday, and also the one-hot encoding or the cyclical versions of those features.\n",
    "\n",
    "    :data: Dataframe that contains the a column with the datetime\n",
    "    :onehot: Use onehot encoding if true and cyclical features if false (default = True)\n",
    "    \n",
    "    Returns a Dataframe with either the one-hot encoding or the sine and cosine of the month, weekday and time added\n",
    "    '''\n",
    "    data = data.reset_index()\n",
    "    if onehot == True:\n",
    "        data['Year'] = pd.Categorical(data['Datetime'].dt.year)\n",
    "        data['Month'] = pd.Categorical(data['Datetime'].dt.month)\n",
    "        data['Weekday'] = pd.Categorical(data['Datetime'].dt.weekday)\n",
    "        data['Hour'] =  pd.Categorical(data['Datetime'].dt.hour)\n",
    "        data['Minute'] =  pd.Categorical(data['Datetime'].dt.minute)\n",
    "\n",
    "        year_dummies = pd.get_dummies(data[['Year']], prefix='Year_')\n",
    "        month_dummies = pd.get_dummies(data[['Month']], prefix='Month_')\n",
    "        weekday_dummies = pd.get_dummies(data[['Weekday']], prefix='Weekday_')\n",
    "        hour_dummies = pd.get_dummies(data[['Hour']], prefix='Hour_')\n",
    "        minute_dummies = pd.get_dummies(data[['Minute']], prefix='Minute_')\n",
    "        \n",
    "        data = data.merge(year_dummies, left_index = True, right_index = True)\n",
    "        data = data.merge(month_dummies, left_index = True, right_index = True)\n",
    "        data = data.merge(weekday_dummies, left_index = True, right_index = True)\n",
    "        data = data.merge(hour_dummies, left_index = True, right_index = True)\n",
    "        data = data.merge(minute_dummies, left_index = True, right_index = True)\n",
    "        \n",
    "    else: \n",
    "        dates = data['Date'].values\n",
    "        weekdays = []\n",
    "        months = []\n",
    "        hours = []\n",
    "        minutes = []\n",
    "\n",
    "        for d in dates:\n",
    "            year, month, day = (int(x) for x in d.split('-'))\n",
    "            ans = dt.date(year, month, day)\n",
    "            weekdays.append(ans.isocalendar()[2])\n",
    "            months.append(month)\n",
    "\n",
    "        for t in data['Time']:\n",
    "            hour, minute, second = (int(x) for x in t.split(':'))\n",
    "            hours.append(hour)\n",
    "            minutes.append(minute)\n",
    "        \n",
    "        data['Weekday'] = weekdays\n",
    "        data['Month'] = months\n",
    "        data['Hour'] = hours\n",
    "        data['Minute'] = minutes\n",
    "        data['Weekday_sin'] = np.sin(data['Weekday'] * (2 * np.pi / 7))\n",
    "        data['Weekday_cos'] = np.cos(data['Weekday'] * (2 * np.pi / 7))\n",
    "        data['Month_sin'] = np.sin(data['Month'] * (2 * np.pi / 12))\n",
    "        data['Month_cos'] = np.cos(data['Month'] * (2 * np.pi / 12))\n",
    "        data['Hour_sin'] = np.sin(data['Hour'] * (2 * np.pi / 24))\n",
    "        data['Hour_cos'] = np.cos(data['Hour'] * (2 * np.pi / 24))\n",
    "        data['Minute_sin'] = np.sin(data['Minute'] * (2 * np.pi / 60))\n",
    "        data['Minute_cos'] = np.cos(data['Minute'] * (2 * np.pi / 60))\n",
    "        \n",
    "    data = data.set_index('Datetime')\n",
    "    return data\n",
    "\n",
    "\n",
    "def predict(data, location, pred_params, N_boost=100):\n",
    "    '''\n",
    "    Predict the amount of visits using XGBoost\n",
    "    \n",
    "    :data: Dataframe with all the data\n",
    "    :location: The location of the park to make predictions for\n",
    "    :pred_params: A list of the names of the predictor variables\n",
    "    :N_boost: Number of boost rounds during training (default = 100)\n",
    "    \n",
    "    Returns nothing (yet)\n",
    "    '''\n",
    "    # Select data for a specific park\n",
    "    data = data[data['Location'] == location]\n",
    "    \n",
    "    # Split the data into input and output variables\n",
    "    X = data[pred_params]\n",
    "    y = data['Visits']\n",
    "\n",
    "    # Split the data into test and train sets\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y,\n",
    "                          test_size = 0.3, random_state = 123)\n",
    "\n",
    "    # Convert test and train set to DMatrix objects\n",
    "    train_dmatrix = xgb.DMatrix(data = train_X, label = train_y)\n",
    "    test_dmatrix = xgb.DMatrix(data = test_X, label = test_y)\n",
    "    \n",
    "    # Set parameters for base learner\n",
    "    params = {\n",
    "        'booster': 'gblinear',\n",
    "#         'colsample_bynode': 0.8,\n",
    "        'learning_rate': 1,\n",
    "#         'max_depth': 15,\n",
    "#         'num_parallel_tree': 100,\n",
    "        'objective': 'reg:squarederror',\n",
    "#         'subsample': 0.8,\n",
    "#         'tree_method': 'gpu_hist'\n",
    "    }\n",
    "\n",
    "    # Fit the data and make predictions\n",
    "    model = xgb.train(params = params, dtrain = train_dmatrix, num_boost_round = N_boost)\n",
    "    pred = model.predict(test_dmatrix)\n",
    "    predictions = pd.DataFrame({'Predicted visitors': pred,\n",
    "                                'Actual visitors': test_y})\n",
    "    predictions = predictions.clip(lower=0)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, predictions['Predicted visitors']))\n",
    "    mae = mean_absolute_error(test_y, predictions['Predicted visitors'])\n",
    "    print(\"RMSE : % f\" %(rmse))\n",
    "    print(\"MAE : % f\" %(mae))\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55854f",
   "metadata": {},
   "source": [
    "### Reading in filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca1b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\my-r-env\\lib\\site-packages\\ipykernel_launcher.py:1: DtypeWarning: Columns (15,16,20,21,22,23,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\olivi\\anaconda3\\envs\\my-r-env\\lib\\site-packages\\ipykernel_launcher.py:42: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n"
     ]
    }
   ],
   "source": [
    "df_Weather2020 = preprocessWeather(\"KNMI (Weather) 2020-2021/uurgeg_240_2011-2020.txt\")\n",
    "df_Weather2021 = preprocessWeather(\"KNMI (Weather) 2020-2021/uurgeg_240_2021-2030.txt\")\n",
    "df_resono = preprocessResono(\"resono_2020_2022.csv\")\n",
    "df_holiday = preprocessHoliday('holidays.csv')\n",
    "\n",
    "df_weather = mergeWeatherFiles(df_Weather2020, df_Weather2021)\n",
    "df_resono_weather = mergeWeatherResonoHoliday(df_resono, df_weather, df_holiday)\n",
    "dataframe = Target_OneHotEncoding(df_resono_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b226ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lines add the complete date to a new column, used for merging with weather/holidays\n",
    "\n",
    "# dataframe[\"Date\"] = dataframe[\"Date\"].astype('str')\n",
    "# dataframe['Datetime']=pd.to_datetime(dataframe.Date + ' ' + dataframe.Time, format='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5729926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = remove_outliers(dataframe[['Visits']])\n",
    "df_no_outliers_int = interpolate_df(df_no_outliers, backfill=False)\n",
    "\n",
    "df_resono_no_outliers = dataframe.copy()\n",
    "df_resono_no_outliers['Visits'] = df_no_outliers_int['Visits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f40af",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3e4eb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Merged_algo_tester.csv')\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "df[\"Date\"] = df[\"Date\"].astype('str')\n",
    "df['Datetime']=pd.to_datetime(df.Date + ' ' + df.Time, format='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "76eb3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = add_time_vars(df, onehot=True)\n",
    "data_aug.drop(['Year', 'Month', 'Day', 'Weekday', \"Holiday_name\", 'Hour', 'Minute'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f9662761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  361.594111\n",
      "MAE :  287.901575\n"
     ]
    }
   ],
   "source": [
    "predictor_cols = data_aug.columns.to_list()[5:]\n",
    "predictions = predict(data_aug, 'Rembrandtpark Zuid', predictor_cols, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4de1185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erasmuspark\n",
      "RMSE :  200.972325\n",
      "MAE :  125.103176\n",
      " -----\n",
      "Oosterpark\n",
      "RMSE :  229.061965\n",
      "MAE :  159.334247\n",
      " -----\n",
      "Rembrandtpark Noord\n",
      "RMSE :  370.582787\n",
      "MAE :  296.160011\n",
      " -----\n",
      "Rembrandtpark Zuid\n",
      "RMSE :  361.594108\n",
      "MAE :  287.901571\n",
      " -----\n",
      "Sarphatipark\n",
      "RMSE :  230.707255\n",
      "MAE :  162.528335\n",
      " -----\n",
      "Vondelpark West\n",
      "RMSE :  188.665261\n",
      "MAE :  126.422488\n",
      " -----\n",
      "Westergasfabriek\n",
      "RMSE :  117.005014\n",
      "MAE :  63.401958\n",
      " -----\n",
      "Vondelpark Oost 1\n",
      "RMSE :  169.673116\n",
      "MAE :  123.051443\n",
      " -----\n",
      "Vondelpark Oost 2\n",
      "RMSE :  166.383776\n",
      "MAE :  115.982125\n",
      " -----\n",
      "Vondelpark Oost 3\n",
      "RMSE :  117.214762\n",
      "MAE :  78.775218\n",
      " -----\n",
      "Westerpark Centrum\n",
      "RMSE :  60.137090\n",
      "MAE :  39.334988\n",
      " -----\n",
      "Westerpark Oost\n",
      "RMSE :  62.460908\n",
      "MAE :  41.863559\n",
      " -----\n",
      "Westerpark West\n",
      "RMSE :  64.843270\n",
      "MAE :  43.416705\n",
      " -----\n"
     ]
    }
   ],
   "source": [
    "locations = data_aug.Location.unique()\n",
    "for location in locations: \n",
    "    print(location)\n",
    "    predict(data_aug, location , predictor_cols, 1000)\n",
    "    print(\" -----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
